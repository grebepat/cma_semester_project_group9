---
title: Cycling Secrets
subtitle: Decoding Bike Messenger Paths for Efficiency
author: Maurin Huonder and Patrick Greber
date: 2024-06-23
format: 
  html:
    code-fold: true
    toc: true
    toc-location: left
    toc-depth: 2
lang: en  
bibliography: bibliography.bib
execute:
  warning: false
  message: false
  cache:   true
  echo:    false
  output:  false
---

```{=html}
<style>
body {
text-align: justify}
</style>
```
```{r install required packages}

options(repos = c(CRAN = "https://cran.rstudio.com"))

install.packages("pacman")
library("pacman")


p_install("dplyr", force = FALSE)
p_install("ggplot2", force = FALSE)
p_install("readr", force = FALSE)
p_install("tidyr", force = FALSE)
p_install("sf", force = FALSE)
p_install("terra", force = FALSE)
p_install("tmap", force = FALSE)
p_install("zoo", force = FALSE)
p_install("units", force = FALSE)
p_install("patchwork", force = FALSE)
p_install("tidyverse", force = FALSE)
p_install("leaflet", force = FALSE)
p_install("shiny", force = FALSE)
p_install("XML", force = FALSE)
p_install("lubridate", force = FALSE)
p_install("ggh4x", force = FALSE)
p_install("forcats", force = FALSE)
p_install("purrr", force = FALSE)
p_install("viridis", force = FALSE)
p_install("httr", force = FALSE)
p_install("hereR", force = FALSE)
p_install("sp", force = FALSE)
p_install("ggpubr", force = TRUE)
p_install("png", force = FALSE)
p_install("grid", force = FALSE)
p_install("raster", force = FALSE)
p_install("gridExtra", force = FALSE)
p_install("RColorBrewer", force = FALSE)
p_install("ggridges", force = FALSE)
p_install("agricolae", force = FALSE)


```

```{r load necessary libraries}
#| echo: true

## loading necessary libraries

library("ggh4x")
library("dplyr")
library("ggplot2")
library("tidyr")
library("sf")
library("sp")
library("terra")
library("tmap")
library("zoo")
library("tidyverse")
library("leaflet")
library("XML")
library("lubridate")
library("forcats")
library("httr")
library("hereR")
library("png")
library("gridExtra")
library("RColorBrewer")
library("purrr")
library("ggridges")
library("agricolae")


```

## Abstract

This work explores the possibility of determine the perception of route choice of bike messengers in the city of Zurich. This is done by comparing chosen trajectories with auto generated alternative trajectories. We compare paths of chosen routes (deliveries) with a generated set of modeled routes (choice-set/alternatives) in terms of distance traveled, slope and street width. Our analysis is based on 95 shift performed by 2 messengers. Street network and type and width were taken from the Swisstlm3d data set. For further attributes such as slope and height, the DHM25 was considered.

## Introduction

Route choice models play an important role in many transport applications, for example, intelligent transport systems, GPS navigation and transportation planning [@frejinger_route_2007]. Modeling route choice behavior is essential, given the possibility to appraise travelers perceptions of route characteristics and to forecast travelers' behavior under hypothetical scenarios [@prato_route_2009]. Route choice models can assess travelers' perceptions of various route characteristics such as distance, travel time, cost, number of traffic lights and road types, and relate the results to the individuals' characteristics (e.g. gender, age, income and trip purpose) and can not only help analyzing and understanding travelers' behavior, but also constitute the essential part of traffic assignment methods. Several studies have used route choice modelling to investigate preferences of cyclists in cities for different purposes such as effectiveness of investments in bicycle infrastructure [@hood_gps-based_2011]. @skov-petersen_how_2018-1 investigated route choices by cyclists in Copenhagen (Denmark). The authors found that cyclists expressed a negative utility for length and turns, indicating a preference for shorter and more direct routes. Furthermore they were sensitive to factors such as length, cycling the wrong way, turn frequency, and terrain gradient.

@broach2012cyclists applied various route choice methods to generate routes in Portland. The results reported in the study showed that only 25% of the generated routes replicated the actual routes, and 42.3% of the routes with an 80% overlap. @hood_gps-based_2011 applied the simulation method to generate routes (the doubly stochastic method) in San Francisco. In contrast to other studies, they added environmental and socioeconomic variables to the cost function, such as crime hot-spots, light and weather conditions. However, as in @broach2012cyclists, the capture rates were very low (around 30%). @menghini2009route used the angle elimination method to generate routes in Zurich. The cost function used was limited to driving distance. In the study by @halldorsdottir2014efficiency in Copenhagen, the cost functions included land use and road type. They added a random component to these values to create a representative route choice set. The coverage results (70 %) were better compared to the previous studies.

This work takes a different approach, exploring the route choices of bike messengers instead of analyzing the route choice of commuters or leisure cyclists. Analyzing the route choices of bike messengers compared to ordinary cyclists can provide insights into efficiency and safety. Due to the fact that bike messengers, are often under time pressure and have a excellent knowledge of the street network, they may choose faster routes, even if they are longer in terms of distance. Additionally, as experienced cyclists, bike messengers can also choose safer or less traveled routes, which can lead to conclusions for the general safety of all cyclists in cities. Furthermore, routes chosen by bike messengers can offer important data on the usage of the city's cycling infrastructure. This can guide decisions on where to focus improvements and enhance route planning and traffic management.

## Research Questions

1.  Do bike messengers always choose the shortest possible route during their deliveries?

2.  How do street network attributes influence the route choice behavior of bike messengers in Zurich?

## Data

### Context Data

All contextual data for enriching the route network is sourced from open-source platforms. SwissTLM3D[^1] provided the street network, street type, and width. The digital terrain model DHM25[^2] was used for obtaining the slope of the streets. DHM25 is available with a resolution of 0.5 meters. The contextual data was preprocessed using Quantum GIS Version 3.34.5. All spatial data has been clipped to the outline of the city of Zurich beforehand.

[^1]: https://www.swisstopo.admin.ch/de/landschaftsmodell-swisstlm3d

[^2]: https://www.swisstopo.admin.ch/de/hoehenmodell-dhm25

```{r import spatial data}


## All Spatial Data is stored in a geopackage called basic_data. Basic_data consists of several layers such as the street network, surface type or housing footprint. The layers were preprocessed and cliped to the extent of the city outline of zurich using Quantum GIS Version 3.34.5


## Show layers in basic_data.gpkg
st_layers("gis_files/basic_data.gpkg")


## Import street network from zurich, based on the swisstlm3d
streets <- read_sf("gis_files/basic_data.gpkg", "street_network_z") |> 
   select(objektart, geom) |> 
  mutate(
    objektart = as.factor(objektart),
    width = as.numeric(substr(objektart, start = 1, stop = 1)),
  ) |> 
  na.omit()


## Import city border of zurich
outline <- read_sf("gis_files/basic_data.gpkg", "city_outline")


## Import housing footprint of zurich
housing <- read_sf("gis_files/basic_data.gpkg", "housing_footprint") |> 
   select(objektart, geom) |>
  mutate(
    objektart = as.factor(objektart)
  )


## Import surface type of zurich
surface <- read_sf("gis_files/basic_data.gpkg", "surface_type") |> 
   select(art, geom) |> 
  mutate(
    art = as.factor(art)) |> 
 filter(art == "fliessendes Gewässer" | art == "stehendes Gewässer" | art == "Strasse, Weg" | art == "Verkehrsinsel") |> 
  na.omit()


## Import digital height model DHM25, a set of data representing the 3D form of the earth’s surface without vegetation and buildings
height <- terra::rast("gis_files/dhm25_zh.tif")


```

### GPS Data

We utilized GPS data collected with the fitness-tracking-app Strava[^3] . The data was collected by two bike messengers in Zurich and conducted as GPX files. The two messengers have been assigned aliases for the purpose of this analysis. They are referred to as `donner` and `raeubertochter`. The data encompasses 95 shifts, with each shift including multiple trajectories/deliveries. The raw data contains a total number of xyz data points. The shifts vary in terms of distance traveled, working hours, season, weather and the number of deliveries. The available movement data consists of a total of 821’770 gps points tracked between 01.09.2022 09:39:33 and 06.05.2024 18:16:19.

[^3]: https://www.strava.com/dashboard

Due to the large amount of data and our limited access to the later used API by `here`, we reduce the data set to one shift `F1` per messenger. Raw gps data per messenger for the shift F1 is shown in @fig-raw_data.

-   The reduced movement data of `raeubertochter` extends from 23.10.2023 12:59:44 to 23.10.2023 17:51:21, and consists of a total of **7102 gps points**.

-   The reduced movement data of `donner` extends from 30.01.2024 10:21:41 to 30.01.2024 22:14:27 and consists of a total of **4597 gps points**.

```{r import raw gps data}
#| echo: true


## generate a list of all filenames including the path from the subfolder they are stored in
file <- list.files("gps_files_shared", recursive = TRUE, pattern = "\\.gpx$", full.names = TRUE)


## Function to extract messenger and id from file path
extract_info <- function(file) {
  messenger <- as.factor(gsub(".*/gps_files_([^/]+)/.*", "\\1", file))
  id <- as.factor(paste(gsub('.*/(.*).gpx','\\1', file), gsub(".*/gps_files_([^/]+)/.*", "\\1", file), sep = "_"))
  list(messenger = messenger, id = id)
}


## Function to process each file
process_file <- function(file) {
  df <- st_read(file, "track_points")
  
  info <- extract_info(file)
  df$messenger <- info$messenger
  df$id <- info$id

  df_sf <- st_as_sf(df, coords = c("lon", "lat"), crs = 4326, remove = FALSE)
  df_sf <- st_transform(df_sf, crs = 2056)
  df_sf$shift <- gsub('.*/(.*).gpx','\\1', file)
  df_sf$x <- st_coordinates(df_sf)[,1]
  df_sf$y <- st_coordinates(df_sf)[,2]
  df_sf <- select(df_sf, id, messenger, shift, time, x, y, ele, geometry)
  df_sf$origin <- file
  df_sf
}


## Apply the function to each file using purrr's map function
single_routes <- purrr::map(file, process_file)


## Combine all results
all_routes <- reduce(single_routes, bind_rows)
save(all_routes, file = "rda_files/all_routes.rda")


## Seperate file into raeubertochter and donner and save output for visualizations under preprocessing.qmd
raeubertochter_raw <- filter(all_routes, messenger == "raeubertochter")
save(raeubertochter_raw, file = "rda_files/raeubertochter_raw.rda")

donner_raw <- filter(all_routes, messenger == "donner")
save(donner_raw, file = "rda_files/donner_raw.rda")


## Our raw data covers one shift per messenger, a total of 11'699 fixes were recorded:

### raeubertochter: 23.10.2023, 12:59:44 to 06.05.2024, 18:16:19, 654554 fixes
### donner: 01.09.2022, 09:39:33 to 20.02.2024 20:55:54, 167216 fixes

```

::: {#fig-raw_data layout-ncol="2"}
![raeubertochter](figures/raeubertochter_raw.png){#fig-raeubertochter_raw .lightbox}

![donner](figures/donner_raw.png){#fig-donner_raw .lightbox}

Raw gps data reduced to the shift F1 for `raeubertochter` and `donner`
:::

We assess the tracking intervals from `raeubertochter` and `donner` as both used different tracking devices. The analysis later allows for an appropriate definition of a threshold for the segmentation of the raw data into separated trajectories. Both messengers have similar tracking intervals, with mean time differences between fixes of 2.91 seconds for `donner` and 1.04 seconds for `raeubertochter`. Mean time difference was estimated after removing values over 30 seconds to get a clearer view on average tracking intervals. The tracking intervals are shown in @fig-sampling and illustrate that most gps points follow eachother within 10 seconds.

```{r assessing sampling intervals}
#| echo: true


## If a larger sampling grid is needed: selecting every 10th row from  movement data:
###all_routes <- all_routes[seq(from = 1, to = #nrow(all_routes), by = 5), ]


## calculate rowwise time difference
all_routes <- all_routes |> 
    group_by(id) |> 
    mutate(
    time_difference = as.numeric(difftime(time, lag(time), units = "secs"))) |>
    ungroup()


## How do the time difference differ between messengers?
all_routes |> 
  group_by(messenger) |> 
  filter(time_difference <= 30) |> # remove outliers to get a clearer view on the average sampling interval
  summarise(
    mean <- mean(time_difference, na.rm = T)
    )

## donner: 2.91, raeubertochter: 1.04
## Both with similar time difference between fixes, raeubertochter with slightly shorter intervals


```

::: {#fig-sampling layout-ncol="1"}
![](figures/sampling_intervall.png){.lightbox}

Assessing tracking intervals for `donner` and `raeubertochter`
:::

## Methods

### From Dots to Drops: Segmenting GPS Fixes into Deliveries

The segmentation of GPS data into different segments was achieved by analyzing the time differences between consecutive data points. Since the Strava-App data already eliminates most static points, it allowed us to rely solely on significant time gaps for the segmentation. Thus, a moving time window was created for each route, and the mean time difference was calculated for each messenger. A new segment was then defined as any instance where the mean time difference exceeded a threshold of 20 seconds. A total of 112 trajectories was computed.

The data was further refined by removing static rows and any segments shorter than two minutes resulting in the exclusion of 54 segments. Each segment was then assigned a `segment_ID`. The number of differentiated segments was calculated for each messenger, resulting in 36 deliveries for `donner`, and 22 deliveries for `raeubertochter` as shown in @fig-seg_data. A total of 1162 segments for `donner` and 1662 segments for `raeubertochter` would have been separated, if all messenger data was included in the analysis.

```{r segmenting deliveries}
#| echo: true

## For seperating the gps data into different segments, we analyse time differences between them. As strava data already removes most of the static points we're in no need to calculate mean_step's but can solely relay on big time gaps.


## create a moving time window
all_routes_seg <- all_routes |> 
   group_by(id) |> 
   mutate(
        nMinus2 = difftime(time, lag(time, 2)), 
        nMinus1 = difftime(time, lag(time,1)),  
        nPlus1  = difftime(lead(time, 1), time), 
        nPlus2  = difftime(lead(time, 2), time)  
    )


## calculate rowwise mean distance per messenger
all_routes_seg <- all_routes_seg |> 
    group_by(id) |>
    mutate(
        timeMean = (nMinus2 + nMinus1 + nPlus1 + nPlus2) / 4
    ) |>
    ungroup()


## create a new column static, based on time_difference (over 20s time difference)
all_routes_seg <- all_routes_seg |> 
  mutate(new_segment = timeMean > 20)

## As strava already removed most static points, we're able to seperate segments via time_difference only. We work with a treshold t of 20 seconds.


## it assigns unique IDs based on the column static
rle_id <- function(vec) {
    x <- rle(vec)$lengths
    as.factor(rep(seq_along(x), times = x))
}


## removes static rows
all_routes_seg <- all_routes_seg |>
    mutate(temp_id = rle_id(new_segment)) |> 
    filter(!new_segment)

length(unique(all_routes_seg$temp_id))

## remove segments shorter than two minuntes
all_routes_seg <- all_routes_seg |> 
  group_by(temp_id) |> 
  mutate(duration = difftime(max(time), min(time))
  ) |> 
  filter(!duration < 120) |> 
  ungroup()

length(unique(all_routes_seg$temp_id))

## Assining new segment_id starting at one, credits to: https://stackoverflow.com/questions/39650511/r-group-by-variable-and-then-assign-a-unique-id
all_routes_seg <- all_routes_seg |> 
  group_by(temp_id, messenger) |> 
  mutate(segment_id = as_factor(cur_group_id())) |> 
  ungroup() |> 
  select(-temp_id)

save(all_routes_seg, file = "rda_files/all_routes_seg.rda")


## how many segments have been differentiated?
all_routes_seg |> 
  group_by(messenger) |> 
  summarise(length(unique(segment_id)))

## donner with 1162 deliveries
## raeubertochter with 1662 deliveries


## filter segments according to messenger
raeubertochter_seg <- filter(all_routes_seg, messenger == "raeubertochter")
save(raeubertochter_seg, file = "rda_files/raeubertochter_seg.rda")

donner_seg <- filter(all_routes_seg, messenger == "donner")
save(donner_seg, file = "rda_files/donner_seg.rda")


```

::: {#fig-seg_data layout-ncol="2"}
![raeubertochter n = 22](figures/raeubertochter_seg.png){#fig-raeubertochter_seg .lightbox}

![donner n = 36](figures/donner_seg.png){#fig-donner_seg .lightbox}

segmented gps data from `raeubertochter` and `donner`
:::

### Lost in Transit: Tackling Tunnel GPS Blackouts for Bike Messenger  

In the analysis, we identified segments, that were incorrectly separated. The false separation was caused by the loss of the GPS signal in a cycle tunnel between station Enge and the sports facility Sihlhölzli. The lost signal produced tracking intervals of more than 20 seconds and led to incorrect segmentation. In the following, we solve this problem using a spatial approach to reverse the incorrect segmentation.

1.  The tunnel is located at the bottom half of @fig-raeubertochter_seg_context. We see two segments (green / yellow), which were wrongfully separated as they represent the same delivery.
2.  First we extracted the starting and endpoints of each delivery @fig-start_endpoints. Additionally, a buffer around the entry and exit points of the tunnel was generated. We then overlaid the point feature with the tunnel buffer to identify segments with starting and endpoints near the tunnel @fig-overlay.
3.  Lastly we compared `segment_id`s of the identified delivery start- and endingpoints close to the tunnel. If an endpoint of `segment_id` `n` and a starting point of `segment_id` `n+1` were both within their respective buffer, a merge of segments was conducted @fig-merged.

For F1, two segments (`segment_id` 49 & 50) were identified and merged back together.

```{r tackling tunnel gps blackouts}
#| echo: true


## problem: we loose GPS signal in the bicycle tunnel from Enge to Sihlhölzli. Our segmentation splits the trajectories into two separate deliveries, even though it's the same route. We try to recognize split segments that we're falsely segmented:
all_routes_seg_tunnel <- all_routes_seg


## Create entry and exit points at the tunnel. For future project, there might be a data set with tunnel entities, where we could extract the entry and exit points automatically
tunnel_exit <- st_sfc(st_point(c(2682368, 1246996)), crs = 2056)
tunnel_entry <- st_sfc(st_point(c(2682592, 1246751)), crs = 2056)


## create a buffer around the tunnel entry and exit,
# tunnel_points <- st_sfc(tunnel_entry, tunnel_exit, crs = 2056)
buffer_entry <- st_buffer(tunnel_entry, dist = 50)
buffer_exit <- st_buffer(tunnel_exit, dist = 50)


segment_endpoints <- all_routes_seg_tunnel %>%
  group_by(segment_id) %>%
  summarize(start_point = first(geometry), end_point = last(geometry))


# Check intersection with buffers
segment_endpoints <- segment_endpoints %>%
  mutate(
    end_in_entry_buffer = as.factor(st_intersects(end_point, buffer_entry, sparse = FALSE)),
    start_in_exit_buffer = as.factor(st_intersects(start_point, buffer_exit, sparse = FALSE))
  )


# Compare adjacent segment IDs
matched_segments <- segment_endpoints |> 
  arrange(segment_id) |> 
  mutate(same = (end_in_entry_buffer == TRUE & lead(start_in_exit_buffer) == TRUE) | (start_in_exit_buffer == TRUE & lag(end_in_entry_buffer) == TRUE)
         )


# Filter segments where endpoints are in the respective buffers and segment IDs follow each other
wrong_segments <- matched_segments |> 
  filter(same == TRUE) |> 
  select(segment_id, same) |> 
  st_drop_geometry()


wrong_segments$new_segment_id <- NA


for (i in seq(1, nrow(wrong_segments), by = 2)) {
  wrong_segments$new_segment_id[i:(i + 1)] <- wrong_segments$segment_id[i]
}


## create a table with falsely seperated segment_id's
lookup_table <- wrong_segments |> 
  select(segment_id, new_segment_id)  |> 
  distinct() # replace duplicates


## We recognized one falsely separated trajecotry. Segment 49 and 50 we're separated but should be kept together


## In this case, we could merge the segments back together manually. but with larger dataset, this might not be feasible. That's why we try a more general approach:


## create a lookup_vector based on our lookup_table. credits go to: https://stackoverflow.com/questions/35636315/replace-values-in-a-dataframe-based-on-lookup-


## This transforms the lookup table into a vector where the names are segment_id and the values are new_segment_id. This vector will be used to quickly find and replace old segment IDs with new ones.
lookup_vector <- setNames(lookup_table$new_segment_id, lookup_table$segment_id)


## match segment_id's with our lookup_vector. For each segment_id in all_routes_seg_tunnel, it checks if that ID is in the lookup vector. If it is, it replaces it with the corresponding new_segment_id from the lookup vector; if not, it keeps the original segment_id
all_routes_seg_tunnel$segment_id_new <- ifelse(all_routes_seg_tunnel$segment_id %in% names(lookup_vector), lookup_vector[match(all_routes_seg_tunnel$segment_id, names(lookup_vector))], all_routes_seg_tunnel$segment_id)


## tidy up our corrected dataframe
all_routes_seg_tunnel_cor <- all_routes_seg_tunnel |> 
  group_by(segment_id_new, messenger) |> 
  mutate(segment_id_cor = as_factor(cur_group_id())) |> 
  select(-segment_id, -segment_id_new) |> 
  ungroup()


## How many deliveries after the correction?
all_routes_seg_tunnel_cor |> 
  group_by(messenger) |> 
  summarise(length(unique(segment_id_cor)))


save(all_routes_seg_tunnel_cor, file = "rda_files/all_routes_seg_tunnel_cor.rda")


## donner with 1162 deliveries
## raeubertochter with 1657 deliveries


## seperate into raeubertochter and save for later visualization in preprocessing.qmd
raeubertochter_cor <- filter(all_routes_seg_tunnel_cor, messenger == "raeubertochter")
save(raeubertochter_cor, file = "rda_files/raeubertochter_cor.rda")


## and donner
donner_cor <- filter(all_routes_seg_tunnel_cor, messenger == "donner")
save(donner_cor, file = "rda_files/donner_cor.rda")

```

::: {#fig-tunnel_workflow layout-ncol="2" layout-nrow="2"}
![wrongfully segmented deliveries](figures/raeubertochter_seg_context.png){#fig-raeubertochter_seg_context .lightbox}

![extracting start and endpoints](figures/start_endpoints_context.png){#fig-start_endpoints .lightbox}

![overlay extracted points with tunnel entry/exit](figures/overlay.png){#fig-overlay .lightbox}

![corrected segments](figures/merged.png){#fig-merged .lightbox}

workflow to correct falsely separated segments
:::

### Pedal powered possibilities: Generating alternative trajectories

We used the HERE API to generate alternative routes. The hereR[^4] package provides an interface to the HERE REST APIs for R. The route function from the hereR package was used to generate alternative routes and enabled the calculation of a maximum of 7 alternative routes per original delivery. Based on the starting and endpoints @fig-original_route of the corrected deliveries `route()` enables calculation of route geometries (LINESTRING) between given pairs of points @fig-alternatives. Routes can be created for various transport modes, as for example car or bicycle. As this step needs a lot of time, the computation was transferred to `preprocessing.R`. The final result consist of the original route combined with one to seven alternative routes @fig-final_result.

[^4]: https://www.rdocumentation.org/packages/hereR/versions/1.0.0.

```{r alternative routing}
#| echo: true

## Alternatives were created in prepocessing.qmd, a file called alternative_final.rda is stored in the global environment
# load alternatives

load("rda_files/alternative_final.rda")


## simplify original dataframe
original <- all_routes_seg_tunnel_cor |> 
  select(messenger, time, geometry, segment_id_cor) |> 
  rename(segment_id = segment_id_cor) |> 
  mutate(
    type = as.character("original"),
    segment_id = as.numeric(segment_id)
    )

  
## simplify alternative datast
alternative <- alternative_final |> 
  select(segment_id, rank,  geometry) |> 
  st_transform(crs = 2056) |> 
  mutate(
    type = as.character("alternative"),
    segment_id = as.numeric(segment_id),
    rank = as.numeric(rank)
  )

#combine the dataset
combined <- bind_rows(original, alternative)


# fill in missing messenger values
combined <- combined |> 
  arrange(segment_id, messenger) |> 
  fill(messenger, .direction = "down")

combined$rank[is.na(combined$rank)] <- 0


## Save combined dataset for visualizations in preprocessing.qmd
save(combined, file = "rda_files/combined.rda")


### As our access to the here API was limited, we were only able to generate a set of alternatives for the shift F1.

## As mentioned above, we have the problem, that we only had limited access to the here API. Therefore we do not have an alternative for every single original trajectory. Before continuoing with our calculations, we need to filter the segments that each have an original route and an alternative


## get every unique segment id from the type original
original_ids <- combined |> 
  filter(type == 'original') |> 
  pull(segment_id) |> 
  unique()


## get every unique segment id from the type alternative
alternative_ids <- combined |>  
  filter(type == 'alternative') |>  
  pull(segment_id) |> 
  unique()


## Find common segment_ids, how many segments are there?
common_ids <- intersect(original_ids, alternative_ids)

length(unique(common_ids))


## Latest computation: 50 matching segments


## Filter the dataframe
filtered_df <- combined |> 
  filter(segment_id %in% common_ids)


# We have a very uneven distribution of gps fixes, a problem we'll solve later

```

::: {#fig-alternative_workflow layout-ncol="1" layout-nrow="3"}
![original route by donner](figures/original_route_start_endpoints.png){#fig-original_route .lightbox .column-page}

![computed alternates using here API](figures/alternative_routing.png){#fig-alternatives .lightbox .column-page}

![original and alternative routes combined](figures/final_result.png){#fig-final_result .lightbox .column-page}

creating alternative routes based on the start and endpoints of the original routes
:::

### Map Matching: Fixing gps points to an existing road network

Map matching denotes the process of assigning positional data (mostly in form of GPS coordinates) to some geographic information about the infrastructure, most commonly road networks [@meister_descriptive_2021]. In our map matching process, we used distance-based matching of a point to a road which return the edges that are closest to the trajectory. Geometrically we unified all roads into a single network. We then located the nearest point on this network for each GPS location used the nearest points to update the original GPS locations, effectively mapping each GPS point to its closest location on the road network.

```{r map matching based on Nils method}
#| echo: true

## since we want to find the closest location on the road over ALL roads
## we need to create a union of the roads first.
street_network <- st_union(streets)


# Now we can get the nearest point for each GPS location
nearest <- st_nearest_points(filtered_df, street_network)
save(nearest, file = "rda_files/nearest.rda")

# The output is a line for each point
# Now we need convert the output from LINE to POINT. 
# This doubles the number of features
near_p <- st_cast(nearest, "POINT")


# now we subset the points. Even numbers are the new, mapmatched points.
near_to <- near_p[c(FALSE,TRUE)]


# Update the geometry of the original points with the new map matched locations
st_geometry(filtered_df) <- st_geometry(near_to)


save(filtered_df, file = "rda_files/filtered_df.rda")

```

::: {#fig-mapmatching layout-ncol="1"}
![](figures/map_matching.png){#fig-map_matching .lightbox}

Map matched gps points ([old coordinates]{style="color:orange;"} / [updated coordinates]{style="color:#9E1FA2;"})
:::

### Data granularity: Uneven distribution of data points

We encountered a challenge due to the unequal distribution of data points / granularity within original routes and alternative routes @fig-uneven. As derived movement parameters are strongly influenced by the sampling rate, uneven amount of data points can skew calculations due to smaller intervals (more fixes) in original routes detecting more differences in height or slope than wider intervals in alternative routing [@laube_how_2011]. Currently, there are often twice as many data points in our [original]{style="color:#9E1FA2;"} segments (rank = 0) than the [alternatives]{style="color:#11E2A1;"} (rank 1 to 7).

```{r uneven distribution gps fixes, .column-margin}
#| echo: true
#| output: true
#| column: margin

## We encounter the problem, that our alternative routes consist of two to three times less data points as our original routes. The denser sampling intervals in our original routes could lead to uneven calculations. For example, smaller intervals could detect more differences in height/slope than the wider sampling interval in the alternative routing


## how many fixes?
overview <- filtered_df |> 
  st_drop_geometry() |> 
  group_by(type, messenger, segment_id, rank) |> 
  summarise(count = n(), 
            count2 = n_distinct(segment_id)) |> 
  mutate(
    type = as.factor(type),
    count = as.numeric(count)
  ) |> 
  na.omit()


overview <- overview |> 
  group_by(type) |> 
  arrange(type) |> 
  select(type, messenger, count, rank) |> 
  as.data.frame()

save(overview, file = "rda_files/overview.rda")

overview |> 
  group_by(type, rank) |> 
  summarise(
    mean = mean(count)
  )

```

::: {#fig-uneven layout-ncol="1"}
![](figures/uneven.png){.lightbox}

Uneven distribution of gps points in original vs. alternative routes
:::

### Interpolation: Computing points along trajectories

To solve the issue of uneven amounts of data points, we interpolated along the trajectories. We simplified the dataset, transformed it into a linestring, and created an interpolation function. We then applied this function to each linestring, resulting in a new point every 10 meters on the trajectory. As we can see in @fig-interpolation, the interpolation resulted in an even distribution of data points between [alternative]{style="color:#11E2A1;"} and [original]{style="color:#9E1FA2;"} routes.

```{r Interpolating trajectories, .column-margin}
#| echo: true
#| output: true
#| column: margin

## Because of the uneven distribution, we decided to interpolate along the original and alternative trajectories


## simplify dataset
filtered_df <- select(filtered_df, -time)


## transform the combined dataset into a linestring. The interpolation will follow these linestrings later
df_lines2 <- filtered_df |> 
  group_by(type, messenger, segment_id, rank) |> 
  summarise(geometry = st_combine(geometry)) |> 
  st_cast("LINESTRING")


## interpolating
## creating a function to interpolate points along lines, there are several functions for interpolation like st_line_sample, sp_sample or gInterpolate by rgeos. 
interpolate_points <- function(geometry, dist=10) {
  len <- st_length(geometry) # how long is the line?
  n_points <- ceiling(len / dist) # how many points will be sampled -> tot_length / distance between points
  st_line_sample(geometry, sample = seq(0, 1, length.out = n_points)) # sequence between 0 and 1 indicating how many points will be sampled based on the length.out = n_points which represents how many points will be sampled
}


# Apply the function to each LINESTRING
# purrr::map: This is a function from the purrr package. The map function applies a function to each element of a list or vector and returns a list. Credits go to Nils ;)
df_lines2$points <- purrr::map(df_lines2$geometry, interpolate_points)


## Unnest the points
df_points <- tidyr::unnest(df_lines2, points)


## create linestring out of interpolated points for later visualizations
df_lines_interp <- df_points |> 
  st_drop_geometry(points)


## remove LINEGEOMETRY
df_points <- df_points |> 
  st_drop_geometry(geometry)


## cast POINTGEOMETRY
df_sf <- st_as_sf(df_points)


## Use st_cast to convert multipoint to single point
df_single_points <- st_cast(df_sf, "POINT")


## somehow have troubles with the geometries, try to solve it:
df_single_points <- st_set_crs(df_single_points, 2056)
df_single_points <- st_transform(df_single_points, crs = 2056)


save(df_single_points, file = "rda_files/df_single_points.rda")

## how many fixes for alternative / original?


## our interpolation generated a dataset with a even distribution between alternatives and originals routes:

df_single_points |> 
  group_by(rank) |> 
  summarise(n = n(),
            n_segments = n_distinct(segment_id),
            fix_per_rank = n / n_segments)


```

::: {#fig-interpolation layout-ncol="2"}
![uneven amount of data points](figures/problem.png){#fig-problem .lightbox}

![even amount of data points](figures/problem_solved.png){#fig-problem_solved .lightbox}

Difference between raw dataset (a) and interpolated version of messenger movement data (b)
:::

In a final step, we enriched messenger movement data with spatial data like height difference, street width, slope and segment length.

```{r enricht trajectory network}
#| echo: true


## We work with 52 trajectories (donner: 33 / raeubertochter: 19)
# Enrich combined dataset with street and environmental data

## buffer point features to intersect them with the street network
traj <- st_buffer(df_single_points, 0.5)


## set crs for polygon layer
traj <- st_set_crs(traj, 2056)


## intersect polygon with street network
traj_width <- st_join(traj, streets, left = TRUE, suffix = "street", join = st_intersects)


## transfrom back to a point layer
traj_width <-  st_centroid(traj_width, crs = 2056)


## Fill missing width's in dataframe
traj_width <- traj_width |> 
  arrange(type, messenger, segment_id, rank) |> 
  fill(objektart, .direction = "down") |> 
  fill(width, .direction = "down")


## Extract height at every point using dhm25
extracted_height <- extract(height, traj_width)
traj_width$height <- round(extracted_height$dhm25_zh,2)


## Extract slope at every point
slope <- terrain(height, v = "slope", unit = "degrees", neighbors = 8)
extracted_slope <- extract(slope, traj_width)
traj_width$slope <- round(extracted_slope$slope,2)


## simplify dataframe
traj_enriched <- traj_width |> 
  select(-objektart)


## Calculations between a pair of points
traj_enriched_final <- traj_enriched |> 
  arrange(type, segment_id, rank) |> 
  group_by(type, segment_id, rank) |> 
  mutate(lead_geom = lead(points),
         travel_dist = sqrt(round(ifelse(!is.na(lead_geom), st_distance(lead_geom, points, by_element = TRUE), 0), 1))^2,
         dist_cumulative = cumsum(ifelse(travel_dist > 0, travel_dist, 0)), 
         tot_segment_length = max(dist_cumulative, na.rm = T),
         height_diff = c(0, diff(height)),
         tot_height_up = sum(ifelse(height_diff > 0, height_diff, 0)),
         tot_height_down = sum(ifelse(height_diff < 0, height_diff, 0)),
         slope_calc = ifelse(travel_dist != 0, (height_diff / travel_dist)*100, 0)
         ) 


## Analysing result
false <- traj_enriched_final |> 
  filter(segment_id == 4 & type == "original", travel_dist < 4.01)
blabla <- traj_enriched_final |> 
  filter(segment_id == 4 & type == "original", travel_dist > 5) 
haha <- df_lines2 |> 
  filter(segment_id == 4 & type == "original")
  
tmap_mode("view")
tm_shape(false) +
tm_dots(col = "gold", size = 0.15)+
tm_shape(blabla) +
  tm_dots(col = "travel_dist") +
  tm_shape(haha) +
  tm_lines()


## somehow the interpolation did not work as expected, there are some overlaying points resulting in a travel_dist of 0.. also euclid distance results in travel_dist shorter than 10m because of turning angles.. we clean the dataset as follows:

# 1.) remove poits with a euclid distance of < 4.5m
# 2.) set travel dist to 10m manually


## Cleaning
traj_cleaned <- traj_enriched_final |> 
  filter(!travel_dist < 4.5) 

  
# repeat calculations
new <- traj_cleaned |> 
  arrange(type, messenger, segment_id, rank) |> 
  group_by(type, messenger, segment_id, rank) |> 
  mutate(lead_geom = lead(points),
         travel_dist = sqrt(round(ifelse(!is.na(lead_geom), st_distance(lead_geom, points, by_element = TRUE), 0), 1))^2,
         dist_cumulative = cumsum(ifelse(travel_dist > 0, travel_dist, 0)), 
         tot_segment_length = max(dist_cumulative, na.rm = T),
         height_diff = c(0, diff(height)),
         tot_height_up = sum(ifelse(height_diff > 0, height_diff, 0)),
         tot_height_down = sum(ifelse(height_diff < 0, height_diff, 0)),
         slope_calc = ifelse(travel_dist != 0, (height_diff / travel_dist)*100, 0)
         )


# setting travel distance to 10m manually, traveled distance was 10m on the line, so euclidiean distance is a little useless here..
new$travel_dist = 10

  

## Calculations over a moving window of 100m (travel distance, 10 points)
## Indexing 100m segments
new <- new |> 
group_by(type, messenger, segment_id, rank) |> 
mutate(
    index = as.integer(cumsum(travel_dist) / 100.1 + 1)
 )


## Transform certain columns
new <- new |> 
  mutate(
    type = as.factor(type),
    segment_id = as.factor(segment_id),
    rank = as.factor(rank),
    index = as.factor(index),
    width = as.factor(width)
  )


## Height differences over first and last point of 100m segments
new <- new |> 
group_by(type, messenger, segment_id, rank, index) |> 
mutate(
   height_diff_100 = last(height) - first(height),
   n = n()
    )
 

alternative_final <- new |> 
      filter(type == "alternative")
    
    
original_final <- new |> 
      filter(type == "original")

```

# Results

### Descriptive Analysis

As shown in @tbl-letters, the original routes are on average shorter compared to the alternatives. With an average segment length of 2229 meters, 385 meters are *saved* per delivery. The longest original segment in Shift `F1` is a delivery of 4039 meters.

For height_up and height_down, cumulative elevation differences between points were calculated, with positive values summarized in height_up and the negative values summarized in height_down. The elevation differences are comparable for both types (original and alternative), with alternatives handling about 4.7 meters more in elevation gain/loss per segment.

To compare the slope between the two types, all trajectories were divided into subsegments of 100 meters in length. Subsequently, average and maximum slope in these subsegments were calculated for every delivery. The average slope in these subsegments is 0.03% for originals and 0.02% for alternatives. The steepest 100-meter subsegment was driven in an original segment and reached 12.3%.

```{r descriptive analysis}
#| echo: true

## Descriptive analysis - segment length
new |> 
  st_drop_geometry() |> 
  group_by(type) |> 
  summarise( Minimum = min(tot_segment_length), Mittelwert = mean(tot_segment_length), Maximum = max(tot_segment_length)
            , Standardabweichung = sd(tot_segment_length), Bereich = (max(tot_segment_length)-min(tot_segment_length)), median(tot_segment_length))


## Descriptive analysis - height up
new |> 
  st_drop_geometry() |> 
  group_by(type) |> 
  summarise(Minimum = min(tot_height_up), Mittelwert = mean(tot_height_up),  Maximum = max(tot_height_up)
            , Standardabweichung = sd(tot_height_up), Bereich = (max(tot_height_up)-min(tot_height_up)), median(tot_height_up))


## Descriptive analysis - height down
new |> 
  st_drop_geometry() |> 
  group_by(type) |> 
  summarise(, Minimum = min(tot_height_down), Mittelwert = mean(tot_height_down), Maximum = max(tot_height_down)
            , Standardabweichung = sd(tot_height_down), Bereich = (max(tot_height_down)-min(tot_height_down)), median(tot_height_down))

save(new, file = "rda_files/new.rda")

## summarise values over 100m subsegments
results <- new %>%
  group_by(type, segment_id, index) %>%
  na.omit() |> 
  summarise(
    n = n(),
     slope_down = mean(ifelse(slope_calc < 0, slope_calc, 0), na.rm = TRUE),
     slope_up = mean(ifelse(slope_calc > 0, slope_calc, 0), na.rm = TRUE),
     max_slope = max((slope_calc), na.rm = TRUE),
    min_slope = min((slope_calc),na.rm = TRUE),
    mean_slope = mean((slope_calc), na.rm = TRUE),
     mean_slope100 = mean((height_diff_100 / (n*10))) *100
     # Mean of 'value' column per group
  )


## Descriptive analysis - average and max. slopes over 100m sub segments
results |> 
  st_drop_geometry() |> 
  group_by(type) |> 
  summarise(meanMittelwert = mean(mean_slope100), meanMinimum = min(mean_slope100), meanMaximum = max(mean_slope100),
            meanMax100 = mean(max_slope),
            maxMax100 = max(max_slope), 
            minMin = min(max_slope))



```

|                           |       | original |       |       | alternative |       |      |
|---------|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|:--------:|
| variable                  | unit  |      min | mean  |  max  |     min     | mean  | max  |
| travel distance           | \[m\] |      584 | 2229  | 4039  |     360     | 2614  | 4640 |
| average gradient per 100m | \[%\] |    -8.88 | 0.03  | 12.3  |    -5.98    | 0.02  | 9    |
| max. + gradient per 100m  | \[%\] |       \- | 4.12  | 75.0  |     \-      | 7.86  | 76.6 |
| height up                 | \[m\] |     0.68 | 20.5  | 87.7  |    0.78     | 25.2  | 113  |
| height down               | \[m\] |    -0.25 | -20.2 | -89.3 |    -0.38    | -24.9 | -138 |

: Comparison of original and alternative routes {#tbl-letters}

### Segment length

Next, we took a closer look at the segment lengths. The segment length of the original routes varies between messengers @fig-segment_length_messenger. On average, a delivery by `raeubertochter` was 2025 meters, while deliveries conducted by `donner` were 1647 meters in average. However, the differences in segment length between the messengers proved to be not significant (t-test, p = 0.166, t = 1.418, df = 32).

```{r segment length by messengers}

## Comparison of length
length_comp <- new |> 
  select(type, messenger, segment_id, rank,  tot_segment_length)

# summarise segment length for each original and alternative segment
df_spread <- length_comp |> 
  group_by(type, messenger, segment_id, rank) |> 
  summarise(
    tot_travel = mean(tot_segment_length)
  ) |> 
  mutate(
    rank = factor(rank, levels = c(0,1,2,3,4,5,6,7))
  )

# how do original segment lengths differ between messengers?
raeubertochter_original <- df_spread |> 
  filter(type == "original" & messenger == "raeubertochter")

donner_original <- df_spread |> 
  filter(type == "original" & messenger == "donner")

# raeubertochter with longer segments, but not statistically significant
t.test(raeubertochter_original$tot_travel, donner_original$tot_travel)

#t(32) = 1.418, p = 0.166

```

::: {#fig-segment_length_messenger layout-ncol="1"}
![](figures/seg_length.png){.lightbox}

Difference in segment lengths by messengers
:::

For each original delivery, between 1 and 7 alternatives were generated. We then examined whether there were differences in segment length between the original routes and alternatives 1 to 7. Among the 57 segments analyzed, the original route was the shortest route in 24 instances, representing 42.1% (compared to all alternatives).

As we can see from the figure @fig-anova, there are differences in segment length between the original and the individual alternatives. However, the pairwise comparison between the original and alternatives 1 to 7 did not reveal any significant differences. It shows that the first alternative (A1) to the original route is the closest in terms of segment length @fig-shortest, with a mean difference of only 43.76 meters (paired t-test, p = 0.193, t = 1.3168, df = 56). The differences in segment length become more pronounced as the number of alternatives increases.

```{r shortest}
#| echo: true

## Are there differences between shortest route generated and route choosen?
comparison1 <- df_spread |> 
  st_drop_geometry() |> 
  filter(rank == 0 | rank == 1) |> 
  group_by(segment_id, rank) |> 
  summarise(mean = mean(tot_travel)) |> 
  spread(key = rank, value = mean) |> 
  rename("original" = "0" , "alternative1" = "1")

t.test(comparison1$alternative1, comparison1$original, paired = T)

## Calculate percentage of shortest route messengers vs. alternatives

comparison2 <- df_spread |> 
  group_by(segment_id) |> 
  summarise(shorter = min(tot_travel[rank == 0]) < min(tot_travel[rank != 0]))

shorter_count <- sum(comparison2$shorter)

## Calculate the total number of unique segment_ids
total_segments <- nrow(comparison2)

## Calculate the percentage
percentage <- (shorter_count / total_segments) * 100


## alternatives and originals almost 50/50. But original mean tot_segment_length 100m shorter than alternative. Alternative routing based on shortest routes... 

# mean difference between original route and shortest generated route at 43m
# in 42% of the times, original was still shortest! so basically no difference between shortest route generated and choosen route!


# So we see slight difference between messengers, but also that alternatives and originals differ.

## But what about rank's? Do more alternatives make sense? or do they change output?

lm = aov(tot_travel ~ rank, data = df_spread)

# par(mfrow = c(2, 2))
# plot(lm)

summary(lm)
summary.lm(lm)  
TukeyHSD(lm)
HSD.test(lm, "rank", console=TRUE)

# significant anova overall, but no pairwise difference between ranks

## ANOVA is significant, but no pairwise difference recognised, Original vs. A5 almost significant. Trend is here, with every alternative, segment_length() gets longer..

```



::: {#fig-anova layout-ncol="1"}
![](figures/anova.png){.lightbox}

Difference in segment lengths by original routes and all alternatives

:::


::: {#fig-shortest layout-ncol="1"}
![](figures/shortest.png){.lightbox}

Difference in segment lengths by original and shortest alternative A1

:::

### Street width
Next, we investigated whether certain types of streets were preferred by messengers based on street width. Since there is no clear procedure for evaluating preferences, we developed an own approach. In each segment, we calculated the share of the different street widths (1, 2, 3, 4, 6, and 8 meters wide) in contrast to the segment length. For each segment (original and alternative) we get percentages on how much a certain street width was used. We then combined the calculated percentage values for all alternatives per segment. For each segment, we obtained a single alternative that summarizes the shares based on street width. The output tibble shows alternative 1 of segment 1 with its street width percentages. This average alternative can then be compared with the actual route taken by the messengers. 

This approach reveals clear preferences or aversions among three street widths. Narrow streets (1 meter wide) are clearly avoided by bike messengers compared to the average alternative, while street widths of two to three meters are clearly preferred @fig-preference.

```{r width}
#| echo: true

# summarize enriched network for street width
width_preference <- new |>
  st_drop_geometry() |> 
  group_by(type, segment_id, rank, width) |> 
  summarise(
    sum = sum(travel_dist, na.rm = T)
  ) 

##Create a complete set of segment IDs and street widths, credits go to: https://stackoverflow.com/questions/73717164/create-all-combinations-of-two-variables-from-two-dataframes-while-keeping-all-o
complete_set <- expand.grid(segment_id = unique(width_preference$segment_id),
                            rank = unique(width_preference$rank),
                           width = as.factor(c(1,2,3,4,6,8)),
                           type = as.factor(c("original", "alternative")))
                           #messenger = as.factor(c("raeubertochter", "donner")))

# create a complete set of street widths
complete_set <- complete_set |> 
  filter(!(type == "original" & rank != 0)) |> 
  filter(!(type == "alternative" & rank == 0)) 

##Left join this set with  original data frame
complete_df <-  full_join(complete_set, width_preference, by = c("type","segment_id", "rank", "width"))


#Replace NA values with 0
complete_df[is.na(complete_df)] <- 0


# a complete set was generated, for every segment, type and rank, shared street widths were calculated

width_preference2 <- complete_df |> 
   group_by(type, segment_id, rank) |>
  mutate(
    width = width,
    sum = as.numeric(sum),
    n = n(),
    tot = sum(sum),
    perc = (sum / tot) * 100
  ) |> 
  na.omit()



width_preference2 <- width_preference2 |> 
   group_by(type, segment_id, rank) |>
  mutate(
    sum_tot = sum(perc)
  )

choice_avg <- width_preference2 |> 
   group_by(type, segment_id, width) |>
 summarise(
   mean_perc = mean(perc)
  ) 


all_together <- choice_avg |> 
  group_by(type, width) |> 
   summarise(
   mean_perc = mean(mean_perc)
  ) 


spread <- spread(all_together, key = type, value = mean_perc)

# do original routes differ from averaged alternatives?
spread$diff <- spread$original - spread$alternative




```

```{r width .column-margin}
#| output: true
#| echo: true
#| column: margin

 width_preference2 |> 
  filter(segment_id == 1 & rank == 1) |> 
   print()

```

::: {#fig-preference layout-ncol="1"}
![](figures/preference.png){.lightbox}

Preferred street widths by messengers compared to mean street widths of all alternatives
:::

### Slope

Lastly, we analyzed how slope differs between original and alternative routes. Similar to @broach2012cyclists, we categorized all 100m subsegments into three different slope categories of 2-4%, 4-6% and >6%. We then calculated mean counts per trajectory to see, if the amount of subsegments within the categories differ between original and alternative routes. We see, that the categories differ slightly (e.g. 2-4% and >6%), but no real difference between original and alternative routes can be distinguished @fig-slope_cat. However, there is a marginal trend to higher amounts of steep subsegments in original routes visible. 

```{r slope}
#| echo: true


# max averae slope per 100m
# mean average_slope per 100m
# counts per category / m per categor

slope <- new |> 
  st_drop_geometry() |> 
  group_by(type, segment_id, rank, index) |> 
  na.omit() |> 
  summarise(
    n = n(),
     mean_slope_up = mean(ifelse(slope_calc > 0, slope_calc, 0), na.rm = TRUE),
    max_slope_up = max(ifelse(slope_calc > 0, slope_calc, 0), na.rm = TRUE),
      mean_slope = mean((slope_calc), na.rm = TRUE),
     max_slope = max((slope_calc), na.rm = TRUE))


slope_long <- slope |> 
  select(type, segment_id, rank, index, mean_slope_up)


slope_result <- slope |> 
  st_drop_geometry() |> 
  group_by(type, segment_id, rank) |> 
  summarise(
    kat1 = sum(mean_slope_up > 2 & mean_slope_up <= 4),
    kat2 = sum(mean_slope_up > 4 & mean_slope_up <= 6),
    kat3 = sum(mean_slope_up > 6)
      )

slope_sum <- pivot_longer(slope_result, -c(type, segment_id, rank))

slope_sum$name <- factor(slope_sum$name, levels = c("kat1", "kat2", "kat3"), labels = c("2-4%", "4-6%", ">6%"))

slope_final <- slope_sum |> 
  group_by(type, segment_id, name) |> 
  summarise(
      mean_count = mean(value) )


```

::: {#fig-slope_cat layout-ncol="1"}
![](figures/category.png){#fig-category .lightbox}

Average number of 100m subsegment per delivery with slopes of 2-4%, 4-6% or >6% 
:::

We further calculated mean slope and maximum slope per subsegment of 100m in each trajectory and created density plots for a better overvoew @fig-slope_density. X-Axis show densities of subsegments while the Y-Axis show mean/max slope in 100m segments in %. No statistical method was applied regarding slope.

::: {#fig-slope_density layout-nrow="2"}
![mean positive slope per 100m subsegments](figures/mean_slope_up.png){#fig-mean_slope_up .lightbox}

![max positive slope per 100m subsegments](figures/max_slope_up.png){#fig-max_slope_up .lightbox}

Mean and Max slopes averaged in 100 meter subsegment
:::

# Discussion
In our study, we demonstrated that bike messengers choose routes that are highly efficient in terms of route length. There are no statistical differences between the shortest possible alternatives and the chosen routes. In 42% of all cases, the original routes were the shortest possible paths. It is intuitive and supported by previous research (e.g. @meister_descriptive_2021, @menghini2009route, @skov-petersen_how_2018) that route length significantly influences route choice. 

Regarding the preference for street width, developing a suitable method proved challenging due to the lack of clear criteria for *preference*.

Concerning slope and height differences, the relevance of such an analysis within the spatial context of Zurich is questionable. While bike messengers do have the freedom to choose their routes, the departure and arrival points are fixed, and in a constrained spatial context like the city of Zurich, elevation changes are difficult to avoid. This might explains the low differences / relevance of slope in the present work, an instance that was observed in @menghini2009route as well. If suitable datasets covering a broader spatial context than Zurich were available, this analysis could yield more insightful results, as observed in other studies (e.g. @skov-petersen_how_2018).

## Limitations

### Map matching

Due to certain constraints and available resources, we adopted a simple approach of distance-based point-to-road matching, which has several limitations [@meister_descriptive_2021]. More sophisticated methods, such as those using Hidden Markov Models (HMMs), are more effective as they consider factors like measurement noise and the road network structure, avoiding simplistic distance-based point-to-road matching [@newson2009hidden]. For implementing map matching in intricate urban road networks, it is crucial to use tools that consider various sources of error linked with position sensors, the vehicle's historical trajectory, topological data about the road network, and the vehicle's direction and speed. These factors collectively help accurately determine the correct link where the vehicle is located [@ochieng_map-matching_2003].

There are also free and open-source solutions for better map matching. However, implementing them in R proved too time-consuming. Future projects could explore APIs from osrm[^5] or valhalla[^6].

[^5]: http://project-osrm.org/
[^6]: https://towardsdatascience.com/map-matching-done-right-using-valhallas-meili-f635ebd17053

### Critical reflection

Uneven distributions and irregular sampling present a challenge. A common approach is transforming unevenly spaced data into equally spaced data using interpolation. However, linear interpolation can introduce biases, data loss, or dilution [@eckner_framework_2014]. When applied to our specific data and research question, these concerns were deemed acceptable.

We tried several approaches to even out the distribution or enrich the dataset or to make the amount / location of gps points irrelevant, all with unsatisfactory results. For future projects, transforming GPS points into an existing road network with edges and points, as shown here could be considered. This was not feasible due to poor map matching in our study.

[^7]: https://r-spatial.org/r/2019/09/26/spatial-networks.html

### Approach in generating alternative trajectories

Using an algorithm to generate alternative trajectories can create some unreasonable trajectories. This error source must be considered as the goal is to generate plausible alternatives. Research aims to improve network-based automatic calibration of the *doubly stochastic* method of @hood_gps-based_2011. This method produces more heterogeneous, attractive, unbiased, and exhaustive choice sets than other methods, yielding more reliable parameter estimates and predictions.

As illustrated in @fig-anova, the average segment length increases with the number of available alternatives. This may be due to the fact that with an increased number of alternatives, more unrealistic and/or lengthy options were generated and illustrates the described problem above.


## Outlook

Due to the extensive data preprocessing, including interpolation, we lacked time to enrich the movement data with other relevant parameters. Future work could include and evaluate the following parameters:

-   Number of intersections in a segment
-   Number of traffic lights/stops
-   Number of left/right turns
-   Proportion of bike lanes/bike routes in a segment
-   Traffic
-   Speed limits

An interesting evaluation would be whether certain messengers are willing to take longer routes to avoid steeper ones. There are likely thresholds where increased route length does not justify reduced steepness anymore.

We have a large and dense dataset that can address many exciting questions. Unfortunately, limited access to the API from `here` prevented us from generating alternatives for all shifts from `raeubertochter` and `donner`. Future work should explore full API access or alternative programs to exploit the dataset's full potential.


### Wordcount

<!-- after installing the wordcountadding, remove the line "#| eval: false" -->

```{r}

library("pacman")
p_install_gh("benmarwick/wordcountaddin")
wordcountaddin::word_count("index.qmd")

```
